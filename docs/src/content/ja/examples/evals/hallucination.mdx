---
title: "例：幻覚 | 評価 | Mastra ドキュメント"
description: 回答における事実の矛盾を評価するための幻覚メトリックの使用例。
---

import { GithubLink } from "@/components/github-link";

# Hallucination

この例では、MastraのHallucinationメトリックを使用して、応答がコンテキストで提供された情報と矛盾しているかどうかを評価する方法を示します。

## 概要

この例では、以下の方法を示します：

1. Hallucinationメトリックを設定する
2. 事実の矛盾を評価する
3. 幻覚スコアを分析する
4. 異なる精度レベルを処理する

## セットアップ

### 環境セットアップ

環境変数を設定してください：

```bash filename=".env"
OPENAI_API_KEY=your_api_key_here
```

### 依存関係

必要な依存関係をインポートします：

```typescript copy showLineNumbers filename="src/index.ts"
import { openai } from '@ai-sdk/openai';
import { HallucinationMetric } from '@mastra/evals/llm';
```

## 使用例

### ハルシネーションなしの例

コンテキストに正確に一致する応答を評価します：

```typescript copy showLineNumbers{5} filename="src/index.ts"
const context1 = [
  'iPhoneは2007年に初めて発売されました。',
  'スティーブ・ジョブズがMacworldで発表しました。',
  'オリジナルモデルは3.5インチの画面を持っていました。',
];

const metric1 = new HallucinationMetric(openai('gpt-4o-mini'), {
  context: context1,
});

const query1 = '最初のiPhoneはいつ発売されましたか？';
const response1 = 'iPhoneは2007年に初めて発売され、スティーブ・ジョブズがMacworldで発表しました。オリジナルのiPhoneは3.5インチの画面を備えていました。';

console.log('例1 - ハルシネーションなし:');
console.log('コンテキスト:', context1);
console.log('クエリ:', query1);
console.log('応答:', response1);

const result1 = await metric1.measure(query1, response1);
console.log('メトリック結果:', {
  score: result1.score,
  reason: result1.info.reason,
});
// 出力例:
// メトリック結果: { score: 0, reason: '応答はコンテキストに正確に一致します。' }
```

### 混合ハルシネーションの例

いくつかの事実に矛盾する応答を評価します：

```typescript copy showLineNumbers{31} filename="src/index.ts"
const context2 = [
  '最初のスター・ウォーズ映画は1977年に公開されました。',
  'ジョージ・ルーカスが監督しました。',
  '映画は世界中で7億7500万ドルを稼ぎました。',
  '映画はチュニジアとイギリスで撮影されました。',
];

const metric2 = new HallucinationMetric(openai('gpt-4o-mini'), {
  context: context2,
});

const query2 = '最初のスター・ウォーズ映画について教えてください。';
const response2 = '最初のスター・ウォーズ映画は1977年に公開され、ジョージ・ルーカスが監督しました。興行収入は10億ドルを超え、全てカリフォルニアで撮影されました。';

console.log('例2 - 混合ハルシネーション:');
console.log('コンテキスト:', context2);
console.log('クエリ:', query2);
console.log('応答:', response2);

const result2 = await metric2.measure(query2, response2);
console.log('メトリック結果:', {
  score: result2.score,
  reason: result2.info.reason,
});
// 出力例:
// メトリック結果: { score: 0.5, reason: '応答はいくつかの事実に矛盾しています。' }
```

### 完全なハルシネーションの例

すべての事実に矛盾する応答を評価します：

```typescript copy showLineNumbers{58} filename="src/index.ts"
const context3 = [
  'ライト兄弟は1903年に初飛行を行いました。',
  '飛行は12秒間続きました。',
  '120フィートの距離をカバーしました。',
];

const metric3 = new HallucinationMetric(openai('gpt-4o-mini'), {
  context: context3,
});

const query3 = 'ライト兄弟はいつ初飛行をしましたか？';
const response3 = 'ライト兄弟は1908年に歴史的な初飛行を達成しました。飛行は約2分間続き、ほぼ1マイルをカバーしました。';

console.log('例3 - 完全なハルシネーション:');
console.log('コンテキスト:', context3);
console.log('クエリ:', query3);
console.log('応答:', response3);

const result3 = await metric3.measure(query3, response3);
console.log('メトリック結果:', {
  score: result3.score,
  reason: result3.info.reason,
});
// 出力例:
// メトリック結果: { score: 1, reason: '応答はコンテキストに完全に矛盾しています。' }
```

