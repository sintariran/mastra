---
title: "例：コンテキスト精度 | Evals | Mastra Docs"
description: コンテキスト情報がどれだけ正確に使用されているかを評価するためのコンテキスト精度メトリックの使用例。
---

import { GithubLink } from "@/components/github-link";

# コンテキスト精度

この例では、Mastra のコンテキスト精度メトリックを使用して、応答が提供されたコンテキスト情報をどれだけ正確に使用しているかを評価する方法を示します。

## 概要

この例では、次の方法を示します：

1. Context Precision メトリックを設定する
2. コンテキスト精度を評価する
3. 精度スコアを分析する
4. 異なる精度レベルを処理する

## セットアップ

### 環境セットアップ

環境変数を設定してください：

```bash filename=".env"
OPENAI_API_KEY=your_api_key_here
```

### 依存関係

必要な依存関係をインポートします：

```typescript copy showLineNumbers filename="src/index.ts"
import { openai } from '@ai-sdk/openai';
import { ContextPrecisionMetric } from '@mastra/evals/llm';
```

## 使用例

### 高精度の例

すべてのコンテキストが関連している応答を評価します：

```typescript copy showLineNumbers{5} filename="src/index.ts"
const context1 = [
  '光合成は太陽光をエネルギーに変換します。',
  '植物は光合成にクロロフィルを使用します。',
  '光合成は副産物として酸素を生成します。',
  'このプロセスには太陽光とクロロフィルが必要です。',
];

const metric1 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {
  context: context1,
});

const query1 = '光合成とは何で、どのように機能しますか？';
const response1 = '光合成は、植物が太陽光をエネルギーに変換し、クロロフィルを使用して副産物として酸素を生成するプロセスです。';

console.log('例 1 - 高精度:');
console.log('コンテキスト:', context1);
console.log('クエリ:', query1);
console.log('応答:', response1);

const result1 = await metric1.measure(query1, response1);
console.log('メトリック結果:', {
  score: result1.score,
  reason: result1.info.reason,
});
// 例の出力:
// メトリック結果: { score: 1, reason: 'コンテキストはすべての関連情報を使用し、無関係な情報を含んでいません。' }
```

### 混合精度の例

一部のコンテキストが無関係な応答を評価します：

```typescript copy showLineNumbers{32} filename="src/index.ts"
const context2 = [
  '火山は地球の地殻の開口部です。',
  '火山は活動中、休止中、または死火山のいずれかです。',
  'ハワイには多くの活火山があります。',
  '太平洋の火のリングには多くの火山があります。',
];

const metric2 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {
  context: context2,
});

const query2 = '火山の異なるタイプは何ですか？';
const response2 = '火山はその活動状態に基づいて、活動中、休止中、または死火山に分類されます。';

console.log('例 2 - 混合精度:');
console.log('コンテキスト:', context2);
console.log('クエリ:', query2);
console.log('応答:', response2);

const result2 = await metric2.measure(query2, response2);
console.log('メトリック結果:', {
  score: result2.score,
  reason: result2.info.reason,
});
// 例の出力:
// メトリック結果: { score: 0.5, reason: 'コンテキストは一部の関連情報を使用し、一部の無関係な情報を含んでいます。' }
```

### 低精度の例

ほとんどのコンテキストが無関係な応答を評価します：

```typescript copy showLineNumbers{58} filename="src/index.ts"
const context3 = [
  'ナイル川はアフリカにあります。',
  'ナイル川は最長の川です。',
  '古代エジプト人はナイル川を利用しました。',
  'ナイル川は北に流れます。',
];

const metric3 = new ContextPrecisionMetric(openai('gpt-4o-mini'), {
  context: context3,
});

const query3 = 'ナイル川はどの方向に流れますか？';
const response3 = 'ナイル川は北に流れます。';

console.log('例 3 - 低精度:');
console.log('コンテキスト:', context3);
console.log('クエリ:', query3);
console.log('応答:', response3);

const result3 = await metric3.measure(query3, response3);
console.log('メトリック結果:', {
  score: result3.score,
  reason: result3.info.reason,
});
// 例の出力:
// メトリック結果: { score: 0.2, reason: 'コンテキストには関連する情報が1つだけあり、それは最後にあります。' }
```

