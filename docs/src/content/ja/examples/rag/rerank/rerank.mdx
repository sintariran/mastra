---
title: "例: 結果の再ランク付け | 検索 | RAG | Mastra ドキュメント"
description: OpenAI埋め込みとベクトル保存のためのPGVectorを使用して、Mastraでセマンティック再ランク付けを実装する例。
---

import { GithubLink } from "@/components/github-link";

# 再ランキング結果

この例では、Mastra、OpenAIの埋め込み、およびベクトルストレージ用のPGVectorを使用して、再ランキングを伴う検索強化生成（RAG）システムを実装する方法を示します。

## 概要

このシステムは、MastraとOpenAIを使用した再ランキングを伴うRAGを実装しています。以下のことを行います：

1. テキストドキュメントを小さなセグメントに分割し、それらから埋め込みを作成します
2. ベクトルをPostgreSQLデータベースに保存します
3. 初期のベクトル類似性検索を実行します
4. Mastraのrerank関数を使用して結果を再ランキングし、ベクトル類似性、意味的関連性、および位置スコアを組み合わせます
5. 初期結果と再ランキングされた結果を比較して改善を示します

## セットアップ

### 環境セットアップ

環境変数を設定してください：

```bash filename=".env"
OPENAI_API_KEY=your_openai_api_key_here
POSTGRES_CONNECTION_STRING=your_connection_string_here
```

### 依存関係

次に、必要な依存関係をインポートします：

```typescript copy showLineNumbers filename="src/index.ts"
import { openai } from '@ai-sdk/openai';
import { PgVector } from '@mastra/pg';
import { MDocument, rerank } from '@mastra/rag';
import { embedMany, embed } from 'ai';
```

## ドキュメント処理

ドキュメントを作成し、チャンクに処理します：

```typescript copy showLineNumbers{7} filename="src/index.ts"
const doc1 = MDocument.fromText(`
market data shows price resistance levels.
technical charts display moving averages.
support levels guide trading decisions.
breakout patterns signal entry points.
price action determines trade timing.
`);

const chunks = await doc1.chunk({
  strategy: 'recursive',
  size: 150,
  overlap: 20,
  separator: '\n',
});
```

## 埋め込みの作成と保存

チャンクの埋め込みを生成し、それをベクターデータベースに保存します:

```typescript copy showLineNumbers{36} filename="src/index.ts"
const { embeddings } = await embedMany({
  values: chunks.map(chunk => chunk.text),
  model: openai.embedding('text-embedding-3-small'),
});

const pgVector = new PgVector(process.env.POSTGRES_CONNECTION_STRING!);
await pgVector.createIndex({
  indexName: 'embeddings',
  dimension: 1536,
});
await pgVector.upsert({
  indexName: 'embeddings',
  vectors: embeddings,
  metadata: chunks?.map((chunk: any) => ({ text: chunk.text })),
});
```

## ベクトル検索と再ランキング

ベクトル検索を実行し、結果を再ランキングします：

```typescript copy showLineNumbers{51} filename="src/index.ts"
const query = 'explain technical trading analysis';

// Get query embedding
const { embedding: queryEmbedding } = await embed({
  value: query,
  model: openai.embedding('text-embedding-3-small'),
});

// Get initial results
const initialResults = await pgVector.query({
  indexName: 'embeddings',
  queryVector: queryEmbedding,
  topK: 3,
});

// Re-rank results
const rerankedResults = await rerank(initialResults, query, openai('gpt-4o-mini'), {
  weights: {
    semantic: 0.5,  // How well the content matches the query semantically
    vector: 0.3,    // Original vector similarity score
    position: 0.2   // Preserves original result ordering
  },
  topK: 3,
});
```

重みは、最終的なランキングにどのように異なる要因が影響を与えるかを制御します：
- `semantic`: 高い値は、クエリに対する意味的理解と関連性を優先します
- `vector`: 高い値は、元のベクトル類似性スコアを優先します
- `position`: 高い値は、結果の元の順序を維持するのに役立ちます

## 結果の比較

初期結果と再ランク付けされた結果の両方を印刷して、改善を確認します:

```typescript copy showLineNumbers{72} filename="src/index.ts"
console.log('Initial Results:');
initialResults.forEach((result, index) => {
  console.log(`Result ${index + 1}:`, {
    text: result.metadata.text,
    score: result.score,
  });
});

console.log('Re-ranked Results:');
rerankedResults.forEach(({ result, score, details }, index) => {
  console.log(`Result ${index + 1}:`, {
    text: result.metadata.text,
    score: score,
    semantic: details.semantic,
    vector: details.vector,
    position: details.position,
  });
});
```

再ランク付けされた結果は、ベクトル類似性とセマンティックな理解を組み合わせることで、検索品質がどのように向上するかを示しています。各結果には以下が含まれます:
- すべての要素を組み合わせた総合スコア
- 言語モデルからのセマンティック関連性スコア
- 埋め込み比較からのベクトル類似性スコア
- 適切な場合に元の順序を維持するための位置ベースのスコア

<br />
<br />
<hr className="dark:border-[#404040] border-gray-300" />
<br />
<br />
<GithubLink
  link={
    "https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/rerank"
  }
/> 