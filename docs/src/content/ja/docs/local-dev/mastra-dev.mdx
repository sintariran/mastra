---
title: "`mastra dev`でエージェントを検査する | Mastra ローカル開発ドキュメント"
description: MastraアプリケーションのためのMastraローカル開発環境のドキュメント。
---
import YouTube from "@/components/youtube";

# ローカル開発環境

Mastraは、ローカルで開発しながらエージェント、ワークフロー、ツールをテストできるローカル開発環境を提供します。

<YouTube id="spGlcTEjuXY" />

## 開発サーバーの起動

Mastra CLIを使用して、Mastra開発環境を起動することができます。以下のコマンドを実行してください:

```bash
mastra dev
```

デフォルトでは、サーバーは http://localhost:4111 で実行されますが、`--port` フラグを使用してポートを変更することができます。

## 開発プレイグラウンド

`mastra dev` は、エージェント、ワークフロー、ツールと対話するためのプレイグラウンドUIを提供します。このプレイグラウンドは、開発中のMastraアプリケーションの各コンポーネントをテストするための専用インターフェースを提供します。

### エージェントプレイグラウンド

エージェントプレイグラウンドは、開発中にエージェントをテストおよびデバッグするためのインタラクティブなチャットインターフェースを提供します。主な機能には以下が含まれます：

- **チャットインターフェース**: エージェントと直接対話して、その応答と動作をテストします。
- **プロンプトCMS**: エージェントのための異なるシステム指示を試すことができます：
  - 異なるプロンプトバージョンのA/Bテスト。
  - 各バリアントのパフォーマンス指標を追跡。
  - 最も効果的なプロンプトバージョンを選択して展開。
- **エージェントトレース**: エージェントがリクエストを処理する方法を理解するための詳細な実行トレースを表示します。これには以下が含まれます：
  - プロンプトの構築。
  - ツールの使用。
  - 意思決定のステップ。
  - 応答の生成。
- **エージェント評価**: [エージェント評価指標](/docs/evals/overview)を設定した場合、以下が可能です：
  - プレイグラウンドから直接評価を実行。
  - 評価結果と指標を表示。
  - 異なるテストケース間でのエージェントのパフォーマンスを比較。

### ワークフロープレイグラウンド

ワークフロープレイグラウンドは、ワークフローの実装を視覚化し、テストするのに役立ちます：

- **ワークフローの視覚化**: ワークフローグラフの視覚化。

- **ワークフローの実行**:
  - カスタム入力データでテストワークフローをトリガー。
  - ワークフローロジックと条件をデバッグ。
  - 異なる実行パスをシミュレート。
  - 各ステップの詳細な実行ログを表示。

- **ワークフロートレース**: 詳細な実行トレースを調べ、以下を示します：
  - ステップバイステップのワークフローの進行。
  - 状態遷移とデータフロー。
  - ツールの呼び出しとその結果。
  - 意思決定ポイントと分岐ロジック。
  - エラーハンドリングと回復パス。

### ツールプレイグラウンド

ツールプレイグラウンドは、カスタムツールを単独でテストすることを可能にします：

- フルエージェントやワークフローを実行せずに個々のツールをテスト。
- テストデータを入力し、ツールの応答を表示。
- ツールの実装とエラーハンドリングをデバッグ。
- ツールの入力/出力スキーマを検証。
- ツールのパフォーマンスと実行時間を監視。

## REST API エンドポイント

`mastra dev` は、ローカルの [Mastra Server](/docs/deployment/server) を介して、エージェントとワークフローのための REST API ルートも起動します。これにより、デプロイ前に API エンドポイントをテストすることができます。すべてのエンドポイントの詳細については、[Mastra Dev リファレンス](/reference/cli/dev#routes) を参照してください。

その後、[Mastra Client](/docs/deployment/client) SDK を活用して、提供された REST API ルートとシームレスに対話することができます。

## ローカル開発アーキテクチャ

ローカル開発サーバーは、外部依存関係やコンテナ化なしで実行できるように設計されています。これは以下によって実現されています：

- **開発サーバー**: [Hono](https://hono.dev)を基盤フレームワークとして使用し、[Mastra Server](/docs/deployment/server)を動作させます。

- **インメモリストレージ**: [LibSQL](https://libsql.org/)メモリアダプターを使用して：
  - エージェントメモリ管理。
  - トレースストレージ。
  - 評価ストレージ。
  - ワークフロースナップショット。

- **ベクトルストレージ**: [FastEmbed](https://github.com/qdrant/fastembed)を使用して：
  - デフォルトの埋め込み生成。
  - ベクトルの保存と取得。
  - セマンティック検索機能。

このアーキテクチャにより、データベースやベクターストアをセットアップすることなく、すぐに開発を開始できると同時に、ローカル環境でも本番環境に近い動作を維持することができます。

### モデル設定

ローカル開発サーバーでは、概要 > モデル設定でモデル設定を構成することもできます。

以下の設定を構成できます：

- **Temperature（温度）**: モデル出力のランダム性を制御します。高い値（0-2）でより創造的な応答が生成され、低い値ではより焦点を絞った決定論的な出力になります。
- **Top P**: トークンサンプリングの累積確率しきい値を設定します。低い値（0-1）では、最も可能性の高いトークンのみを考慮することで、より焦点を絞った出力になります。
- **Top K**: 各生成ステップで考慮されるトークンの数を制限します。低い値では、より少ないオプションからサンプリングすることで、より焦点を絞った出力が生成されます。
- **Frequency Penalty（頻度ペナルティ）**: 以前のテキストでのトークンの頻度に基づいてペナルティを与えることで、繰り返しを減らします。高い値（0-2）では、一般的なトークンの再利用を抑制します。
- **Presence Penalty（存在ペナルティ）**: 以前のテキストに出現したトークンにペナルティを与えることで、繰り返しを減らします。高い値（0-2）では、モデルが新しいトピックについて議論することを促します。
- **Max Tokens（最大トークン数）**: モデルの応答で許可される最大トークン数。高い値ではより長い出力が可能になりますが、レイテンシーが増加する可能性があります。
- **Max Steps（最大ステップ数）**: ワークフローまたはエージェントが停止する前に実行できる最大ステップ数。無限ループや暴走プロセスを防止します。
- **Max Retries（最大再試行回数）**: 失敗したAPI呼び出しやモデルリクエストを諦める前に再試行する回数。一時的な障害を適切に処理するのに役立ちます。


## 概要

`mastra dev` は、本番環境にデプロイする前に、自己完結型の環境でAIロジックを開発、デバッグ、反復することを容易にします。

- [Mastra Dev リファレンス](../../reference/cli/dev.mdx)
